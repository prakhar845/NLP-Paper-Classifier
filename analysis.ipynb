{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e79e0b-404f-46c5-9788-4fe2dd4b0dbd",
   "metadata": {},
   "source": [
    "#### 1. Load Data and Libraries\n",
    "#### At first, we will import the necessary libraries and load the arxiv_data.csv file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6854eb4-cfdb-4879-a1ba-8b0dc6499780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from seaborn) (2.3.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from seaborn) (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\desktop\\nlp_paper_classifier\\tcs_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install nltk\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b074fe27-0bfe-4b7d-96f8-698f5bb0bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                    categories  \n",
       "0           ['cs.CV', 'cs.LG']  \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
       "2           ['cs.CV', 'cs.AI']  \n",
       "3                    ['cs.CV']  \n",
       "4           ['cs.CV', 'cs.LG']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df = pd.read_csv('arxiv_data.csv')\n",
    "\n",
    "df = df[['titles', 'summaries', 'terms']]\n",
    "df.rename(columns={'titles': 'title', 'summaries': 'abstract', 'terms': 'categories'}, inplace=True)\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbde84-377a-4b0d-be8b-48219e888a78",
   "metadata": {},
   "source": [
    "#### 2. Clean the Abstract Text\n",
    "#### Now we would define and apply a function to clean the raw text of the abstracts. This makes the text uniform for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c8009f2-04d4-4bc1-9864-8f34c1fc3b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning complete. Here's a before and after example:\n",
      "\n",
      "Original:\n",
      " Stereo matching is one of the widely used techniques for inferring depth from\n",
      "stereo images owing to its robustness and speed. It has become one of the major\n",
      "topics of research since it finds its applications in autonomous driving,\n",
      "robotic navigation, 3D reconstruction, and many other fields. Finding pixel\n",
      "correspondences in non-textured, occluded and reflective areas is the major\n",
      "challenge in stereo matching. Recent developments have shown that semantic cues\n",
      "from image segmentation can be used to improve the results of stereo matching.\n",
      "Many deep neural network architectures have been proposed to leverage the\n",
      "advantages of semantic segmentation in stereo matching. This paper aims to give\n",
      "a comparison among the state of art networks both in terms of accuracy and in\n",
      "terms of speed which are of higher importance in real-time applications.\n",
      "\n",
      "Cleaned:\n",
      " stereo matching one widely used techniques inferring depth stereo images owing robustness speed become one major topics research since finds applications autonomous driving robotic navigation reconstruction many fields finding pixel correspondences nontextured occluded reflective areas major challenge stereo matching recent developments shown semantic cues image segmentation used improve results stereo matching many deep neural network architectures proposed leverage advantages semantic segmentation stereo matching paper aims give comparison among state art networks terms accuracy terms speed higher importance realtime applications\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Applies basic text cleaning.\"\"\"\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'\\[.*?\\]', '', text) \n",
    "    text = re.sub(r'[^a-z\\s]', '', text) \n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "df['abstract_cleaned'] = df['abstract'].apply(clean_text)\n",
    "\n",
    "print(\"Text cleaning complete. Here's a before and after example:\")\n",
    "print(\"\\nOriginal:\\n\", df['abstract'].iloc[0])\n",
    "print(\"\\nCleaned:\\n\", df['abstract_cleaned'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3e259-12f7-4269-85cc-cf3af5392498",
   "metadata": {},
   "source": [
    "#### 3. Prepare the Labels (Multi-Hot Encoding)\n",
    "#### Finally, would convert the text-based category labels into a numerical format that the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1437db-e647-4323-94e5-7724474b6426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label processing complete.\n",
      "Shape of the new numerical labels: (51774, 1392)\n",
      "Example of the first paper's numerical label vector: [0 0 0 ... 0 0 0]\n",
      "The first 10 class names found: [\"'00']\" \"'00-02']\" \"'00B25']\" \"'00Bxx',\" \"'03B52,\" \"'03B70,\" \"'05B45,\"\n",
      " \"'05C20,\" \"'05C21,\" \"'05C50']\"]\n"
     ]
    }
   ],
   "source": [
    "df['categories_list'] = df['categories'].apply(lambda x: x.split())\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y = mlb.fit_transform(df['categories_list'])\n",
    "\n",
    "print(\"\\nLabel processing complete.\")\n",
    "print(\"Shape of the new numerical labels:\", y.shape)\n",
    "print(\"Example of the first paper's numerical label vector:\", y[0])\n",
    "print(\"The first 10 class names found:\", mlb.classes_[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cea2f-1b3f-422c-9d23-e7f31fc15448",
   "metadata": {},
   "source": [
    "#### We have now successfully preprocessed our data. We have the cleaned text in df['abstract_cleaned'] and the corresponding numerical labels in the y variable, ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ea725-369c-4232-bbd9-0d6244645a0e",
   "metadata": {},
   "source": [
    "#### Next we would be creating a simple baseline model. This will give a performance score that the more complex deep learning model will need to beat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fe478-d5f7-4d11-8d22-e3e950dee0a9",
   "metadata": {},
   "source": [
    "#### 4. Split Data for Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94d773-bda9-42ee-879f-070b7adb8632",
   "metadata": {},
   "source": [
    "#### Now we will split the cleaned text (X) and numerical labels (y) into a training set (to teach the model) and a testing set (to evaluate it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b73073e-d9ec-4dd0-a680-d84cc2e2c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets.\n",
      "Training samples: 41419\n",
      "Testing samples: 10355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['abstract_cleaned']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing sets.\")\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c20340-6d55-44ad-af1b-8fdf5e1e4b15",
   "metadata": {},
   "source": [
    "#### 5. Vectorize Text with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883abc0-48ef-49d6-835e-e60fabe8bebf",
   "metadata": {},
   "source": [
    "#### Now we convert the text into numerical vectors using TfidfVectorizer. The model can only work with numbers, not raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60eb2646-fb68-4628-8c9e-cc60293d4ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text vectorization complete.\n",
      "Shape of the TF-IDF matrix for training data: (41419, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"\\nText vectorization complete.\")\n",
    "print(\"Shape of the TF-IDF matrix for training data:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f16bf-c328-4666-939b-c4a5703a77d4",
   "metadata": {},
   "source": [
    "#### 6. Train and Evaluate the Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b624a-7d53-4423-844f-e895691d6f2a",
   "metadata": {},
   "source": [
    "#### Finally, train a LogisticRegression model. We wrap it in a OneVsRestClassifier to handle the multi-label nature of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f2ccb1-9c34-4e15-89fd-90c7d091e307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the baseline model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 9 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 15 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 23 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 24 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 50 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 54 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 59 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 67 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 73 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 77 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 85 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 91 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 93 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 120 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 133 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 144 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 147 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 158 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 160 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 167 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 176 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 198 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 207 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 236 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 252 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 264 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 266 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 268 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 269 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 278 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 291 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 298 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 305 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 306 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 323 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 324 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 329 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 337 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 348 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 350 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 351 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 355 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 364 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 397 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 404 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 427 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 444 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 450 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 469 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 472 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 511 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 597 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 606 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 607 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 612 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 725 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 728 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 730 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 742 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 793 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 794 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 796 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 805 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 814 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 819 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 828 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 832 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 839 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 844 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 854 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 867 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 873 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 875 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 891 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 895 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 897 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 910 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 913 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 931 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 932 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 939 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 948 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 951 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 958 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 959 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 961 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 970 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 977 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 998 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1007 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1019 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1022 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1051 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1063 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1067 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1071 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1072 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1073 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1076 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1077 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1081 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1082 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1083 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1086 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1093 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1094 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1101 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1112 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1114 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1125 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1127 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1133 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1136 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1138 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1149 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1154 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1156 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1158 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1159 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1165 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1166 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1193 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1201 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1212 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1221 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1222 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1226 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1238 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1245 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1254 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1259 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1276 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1278 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1307 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1315 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1316 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1323 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1327 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1329 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\sklearn\\multiclass.py:90: UserWarning: Label not 1359 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "\n",
      "Baseline Model F1-Score (micro): 0.4405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=42)\n",
    "clf = OneVsRestClassifier(lr)\n",
    "\n",
    "print(\"\\nTraining the baseline model...\")\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"\\nBaseline Model F1-Score (micro): {f1_micro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babdfdb-182d-4822-b958-0dafc4900380",
   "metadata": {},
   "source": [
    "#### Now that we have a baseline score, it's time to build the more powerful deep learning model. This involves preparing the text data in a new way and then building, training, and evaluating the LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a72aa6-b158-41e4-a3ec-0d8d1637d56b",
   "metadata": {},
   "source": [
    "#### 7. Prepare Data for the Deep Learning Model \n",
    "#### We will convert the text into sequences of integers and then pad them so they are all the same length. Neural networks require inputs to have a fixed size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ba4c18-eace-4944-9977-7cba328427b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data has been tokenized and padded.\n",
      "Shape of padded training data: (41419, 200)\n"
     ]
    }
   ],
   "source": [
    "from keras.src.legacy.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(df['abstract_cleaned'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "vocab_size = 10000\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "\n",
    "max_length = 200\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "print(\"Text data has been tokenized and padded.\")\n",
    "print(\"Shape of padded training data:\", X_train_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d33f7-04be-4282-a750-07d846439655",
   "metadata": {},
   "source": [
    "#### 8. Build, Compile, and Train the LSTM Model\n",
    "#### Now we will define the architecture of our LSTM model using Keras. Then, compile it with the correct loss function and optimizer, and finally, train it on our prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67618276-f1e4-46b0-9422-17630762941c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Class Weights: {0: np.float64(0.5007436386680713), 1: np.float64(336.6847772768681)}\n",
      "\n",
      "Training the LSTM model with class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\NLP_Paper_Classifier\\tcs_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 129ms/step - accuracy: 0.1415 - loss: 0.0161 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 2/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 134ms/step - accuracy: 0.1386 - loss: 0.0055 - val_accuracy: 0.3416 - val_loss: 0.0053\n",
      "Epoch 3/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 136ms/step - accuracy: 0.1399 - loss: 0.0055 - val_accuracy: 0.3416 - val_loss: 0.0053\n",
      "Epoch 4/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 127ms/step - accuracy: 0.1416 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 5/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 123ms/step - accuracy: 0.1394 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 6/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 124ms/step - accuracy: 0.1313 - loss: 0.0056 - val_accuracy: 0.3416 - val_loss: 0.0053\n",
      "Epoch 7/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 123ms/step - accuracy: 0.1353 - loss: 0.0055 - val_accuracy: 0.3416 - val_loss: 0.0054\n",
      "Epoch 8/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 126ms/step - accuracy: 0.1309 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 9/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 125ms/step - accuracy: 0.1297 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 10/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 127ms/step - accuracy: 0.1193 - loss: 0.0055 - val_accuracy: 0.3416 - val_loss: 0.0054\n",
      "Epoch 11/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 126ms/step - accuracy: 0.1303 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 12/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 134ms/step - accuracy: 0.1230 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 13/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 145ms/step - accuracy: 0.1248 - loss: 0.0056 - val_accuracy: 0.3416 - val_loss: 0.0054\n",
      "Epoch 14/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 15/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 139ms/step - accuracy: 0.1203 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 16/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 140ms/step - accuracy: 0.1190 - loss: 0.0055 - val_accuracy: 0.3416 - val_loss: 0.0053\n",
      "Epoch 17/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 140ms/step - accuracy: 0.1163 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0053\n",
      "Epoch 18/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 139ms/step - accuracy: 0.1208 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 19/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 140ms/step - accuracy: 0.1179 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0053\n",
      "Epoch 20/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 132ms/step - accuracy: 0.1132 - loss: 0.0055 - val_accuracy: 0.3416 - val_loss: 0.0053\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train.flatten()),\n",
    "    y=y_train.flatten()\n",
    ")\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Calculated Class Weights:\", class_weight_dict)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nTraining the LSTM model with class weights...\")\n",
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=20, # Keep the increased epochs\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    class_weight=class_weight_dict) # <-- APPLY THE WEIGHTS HERE\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f71fb-8264-4690-bdb1-f19113fa3ed3",
   "metadata": {},
   "source": [
    "#### 9. Evaluate the Deep Learning Model\n",
    "#### Finally, now we will make predictions on the test set and evaluate the F1 score. Compare this score to your baseline to see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4ff2b8-3ecd-48ed-8165-01ee2ab817e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step\n",
      "\n",
      "Deep Learning Model F1-Score (micro): 0.0000\n",
      "Baseline Model F1-Score (micro): 0.4405\n",
      "Improvement over baseline: -100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred_probs = model.predict(X_test_pad)\n",
    "\n",
    "y_pred_dl = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1_micro_dl = f1_score(y_test, y_pred_dl, average='micro')\n",
    "\n",
    "print(f\"\\nDeep Learning Model F1-Score (micro): {f1_micro_dl:.4f}\")\n",
    "print(f\"Baseline Model F1-Score (micro): {f1_micro:.4f}\")\n",
    "\n",
    "improvement = ((f1_micro_dl - f1_micro) / f1_micro) * 100\n",
    "print(f\"Improvement over baseline: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c64b8035-40ed-4160-a172-6b391cd96d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model saved as arxiv_classifier_model.h5\n",
      "Tokenizer saved as tokenizer.pickle\n",
      "MultiLabelBinarizer saved as mlb.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model.save('arxiv_classifier_model.h5')\n",
    "print(\"Keras model saved as arxiv_classifier_model.h5\")\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Tokenizer saved as tokenizer.pickle\")\n",
    "\n",
    "with open('mlb.pickle', 'wb') as handle:\n",
    "    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"MultiLabelBinarizer saved as mlb.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66ca5e-50de-491f-b5a1-b0b75c89e55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
